{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from dataclasses import InitVar, dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Iterable, NamedTuple, Sequence, TypeAlias\n",
    "\n",
    "from lightning import pytorch as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit.Chem import Mol\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from chemprop.data.collate import BatchMolGraph, collate_batch\n",
    "from chemprop.data.datapoints import MoleculeDatapoint\n",
    "from chemprop.data.datasets import Datum, MoleculeDataset, MulticomponentDataset, ReactionDataset\n",
    "from chemprop.data.molgraph import MolGraph\n",
    "from chemprop.data.splitting import make_split_indices, split_data_by_indices\n",
    "from chemprop.featurizers import Featurizer, SimpleMoleculeMolGraphFeaturizer\n",
    "from chemprop.models import MulticomponentMPNN, multi\n",
    "from chemprop.nn.agg import Aggregation, MeanAggregation\n",
    "from chemprop.nn.hparams import HasHParams\n",
    "from chemprop.nn.message_passing import BondMessagePassing, MulticomponentMessagePassing\n",
    "from chemprop.nn.metrics import ChempropMetric\n",
    "from chemprop.nn.predictors import Predictor, RegressionFFN\n",
    "from chemprop.nn.transforms import ScaleTransform, UnscaleTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first extend the `MolGraph` class to include a global attribute `w_fp` which is the weight of the learned fingerprint of the molecule when averaging the fingerprints of components in the mixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See also chemprop.data.molgraph.MolGraph\n",
    "class ComponentMolGraph(NamedTuple):\n",
    "    V: np.ndarray\n",
    "    E: np.ndarray\n",
    "    edge_index: np.ndarray\n",
    "    rev_edge_index: np.ndarray\n",
    "    w_fp: float = 1.0\n",
    "    \"\"\"the weight of the component's fingerprint when combining components in the mixture\"\"\"\n",
    "\n",
    "\n",
    "# See also chemprop.data.datasets.Datum\n",
    "class ComponentDatum(NamedTuple):\n",
    "    mg: ComponentMolGraph\n",
    "    V_d: np.ndarray | None\n",
    "    x_d: np.ndarray | None\n",
    "    y: np.ndarray | None\n",
    "    weight: float\n",
    "    lt_mask: np.ndarray | None\n",
    "    gt_mask: np.ndarray | None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batched versions of `MolGraph` and `Datum` are created during collating datapoints. These are also extended, as well as the entire batch representing all components in the mixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See also chemprop.data.collate.BatchMolGraph\n",
    "@dataclass(repr=False, eq=False, slots=True)\n",
    "class BatchComponentMolGraph(BatchMolGraph):\n",
    "    mgs: InitVar[Sequence[ComponentMolGraph]]\n",
    "    w_fps: Tensor = field(init=False)\n",
    "\n",
    "    def __post_init__(self, mgs):\n",
    "        super(BatchComponentMolGraph, self).__post_init__(mgs)\n",
    "        self.w_fps = torch.from_numpy(np.array([mg.w_fp for mg in mgs])).float()\n",
    "\n",
    "    def to(self, device: str | torch.device):\n",
    "        super(BatchComponentMolGraph, self).to(device)\n",
    "        self.w_fps = self.w_fps.to(device)\n",
    "\n",
    "\n",
    "# See also chemprop.data.collate.TrainingBatch\n",
    "class BatchComponentDatum(NamedTuple):\n",
    "    bmg: BatchComponentMolGraph\n",
    "    V_d: Tensor | None\n",
    "    X_d: Tensor | None\n",
    "    Y: Tensor | None\n",
    "    w: Tensor\n",
    "    lt_mask: Tensor | None\n",
    "    gt_mask: Tensor | None\n",
    "\n",
    "\n",
    "# See also chemprop.data.collate.MulticomponentTrainingBatch\n",
    "class MixtureBatch(NamedTuple):\n",
    "    bmgs: list[BatchMolGraph | BatchComponentMolGraph]\n",
    "    V_ds: list[Tensor | None]\n",
    "    X_d: Tensor | None\n",
    "    Y: Tensor | None\n",
    "    w: Tensor\n",
    "    lt_mask: Tensor | None\n",
    "    gt_mask: Tensor | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See also chemprop.data.collate.collate_batch\n",
    "def collate_component(batch: Iterable[Datum]) -> BatchComponentDatum:\n",
    "    mgs, V_ds, x_ds, ys, weights, lt_masks, gt_masks = zip(*batch)\n",
    "\n",
    "    return BatchComponentDatum(\n",
    "        BatchComponentMolGraph(mgs),\n",
    "        None if V_ds[0] is None else torch.from_numpy(np.concatenate(V_ds)).float(),\n",
    "        None if x_ds[0] is None else torch.from_numpy(np.array(x_ds)).float(),\n",
    "        None if ys[0] is None else torch.from_numpy(np.array(ys)).float(),\n",
    "        torch.tensor(weights, dtype=torch.float).unsqueeze(1),\n",
    "        None if lt_masks[0] is None else torch.from_numpy(np.array(lt_masks)),\n",
    "        None if gt_masks[0] is None else torch.from_numpy(np.array(gt_masks)),\n",
    "    )\n",
    "\n",
    "\n",
    "# See also chemprop.data.collate.collate_multicomponent\n",
    "def collate_mixture(batches: Iterable[Iterable[ComponentDatum | Datum]]) -> MixtureBatch:\n",
    "    tbs = [\n",
    "        collate_batch(batch) if isinstance(batch[0], Datum) else collate_component(batch)\n",
    "        for batch in zip(*batches)\n",
    "    ]\n",
    "\n",
    "    return MixtureBatch(\n",
    "        [tb.bmg for tb in tbs],\n",
    "        [tb.V_d for tb in tbs],\n",
    "        tbs[0].X_d,\n",
    "        tbs[0].Y,\n",
    "        tbs[0].w,\n",
    "        tbs[0].lt_mask,\n",
    "        tbs[0].gt_mask,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ComponentDatapoint(MoleculeDatapoint):\n",
    "    w_fp: np.ndarray | None = None\n",
    "    \"\"\"the weight of the molecule's learned fingerprint when averaging in the mixture\"\"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ComponentDataset(MoleculeDataset, Dataset[ComponentMolGraph]):\n",
    "    data: list[ComponentDatapoint]\n",
    "\n",
    "    @property\n",
    "    def w_fps(self) -> np.ndarray:\n",
    "        return np.array([d.w_fp for d in self.data])\n",
    "\n",
    "    def __getitem__(self, idx: int) -> ComponentDatum:\n",
    "        d = self.data[idx]\n",
    "        mg = self.mg_cache[idx]\n",
    "        mg = ComponentMolGraph(w_fp=d.w_fp, *mg)\n",
    "\n",
    "        return ComponentDatum(\n",
    "            mg, self.V_ds[idx], self.X_d[idx], self.Y[idx], d.weight, d.lt_mask, d.gt_mask\n",
    "        )\n",
    "\n",
    "\n",
    "@dataclass(repr=False, eq=False)\n",
    "class MixtureDataset(MulticomponentDataset):\n",
    "    datasets: list[MoleculeDataset | ReactionDataset | ComponentDataset]\n",
    "\n",
    "    def __getitem__(self, idx: int) -> list[ComponentDatum | Datum]:\n",
    "        return [dset[idx] for dset in self.datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureAggregation(nn.Module, HasHParams):\n",
    "    output_dim: int\n",
    "\n",
    "    def __init__(\n",
    "        self, graph_agg: Aggregation, groups: Sequence[Sequence[int]], fp_dims: Sequence[int]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hparams = {\n",
    "            \"cls\": self.__class__,\n",
    "            \"graph_agg\": graph_agg,\n",
    "            \"groups\": groups,\n",
    "            \"fp_dims\": fp_dims,\n",
    "        }\n",
    "        self.graph_agg = graph_agg\n",
    "        self.groups = groups\n",
    "        self.fp_dims = fp_dims\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(\n",
    "        self, Hs: list[Tensor], bmgs: list[BatchComponentMolGraph | BatchMolGraph]\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Aggregate component representations into a mixture representation\"\"\"\n",
    "\n",
    "\n",
    "class WeightedSumAggregation(MixtureAggregation):\n",
    "    @property\n",
    "    def output_dim(self) -> int:\n",
    "        return sum(self.fp_dims[group[0]] for group in self.groups)\n",
    "\n",
    "    def forward(\n",
    "        self, H_vs: list[Tensor], bmgs: list[BatchComponentMolGraph | BatchMolGraph]\n",
    "    ) -> Tensor:\n",
    "        Hs = [self.graph_agg(H_v, bmg.batch) for H_v, bmg in zip(H_vs, bmgs)]\n",
    "        combined_Hs = []\n",
    "        for group in self.groups:\n",
    "            if len(group) == 1:\n",
    "                combined_Hs.append(Hs[group[0]])\n",
    "                continue\n",
    "\n",
    "            group_Hs = torch.stack([Hs[idx] for idx in group])  # n x b x d\n",
    "            group_w_fps = torch.stack([bmgs[idx].w_fps for idx in group])  # n x b\n",
    "            # n: num. components in group, b: num. comp. in batch, d: output dim of message passing\n",
    "            combined_H = torch.einsum(\"nb,nbd->bd\", group_w_fps, group_Hs)\n",
    "            combined_Hs.append(combined_H)\n",
    "        return torch.cat(combined_Hs, 1)\n",
    "\n",
    "\n",
    "class ConcatAggregation(MixtureAggregation):\n",
    "    @property\n",
    "    def components_in_mixture(self) -> set[int]:\n",
    "        return {idx for group in self.groups if len(group) > 1 for idx in group}\n",
    "\n",
    "    @property\n",
    "    def output_dim(self) -> int:\n",
    "        return sum(self.fp_dims) + len(self.components_in_mixture)\n",
    "\n",
    "    def forward(\n",
    "        self, H_vs: list[Tensor], bmgs: list[BatchComponentMolGraph | BatchMolGraph]\n",
    "    ) -> Tensor:\n",
    "        Hs = [self.graph_agg(H_v, bmg.batch) for H_v, bmg in zip(H_vs, bmgs)]\n",
    "        w_fps = torch.stack([bmgs[idx].w_fps for idx in self.components_in_mixture], dim=1)\n",
    "        return torch.cat(Hs + [w_fps], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureMPNN(MulticomponentMPNN):\n",
    "    def __init__(\n",
    "        self,\n",
    "        message_passing: MulticomponentMessagePassing,\n",
    "        agg: MixtureAggregation,\n",
    "        predictor: Predictor,\n",
    "        batch_norm: bool = False,\n",
    "        metrics: Iterable[ChempropMetric] | None = None,\n",
    "        warmup_epochs: int = 2,\n",
    "        init_lr: float = 1e-4,\n",
    "        max_lr: float = 1e-3,\n",
    "        final_lr: float = 1e-4,\n",
    "        X_d_transform: ScaleTransform | None = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            message_passing,\n",
    "            agg,\n",
    "            predictor,\n",
    "            batch_norm,\n",
    "            metrics,\n",
    "            warmup_epochs,\n",
    "            init_lr,\n",
    "            max_lr,\n",
    "            final_lr,\n",
    "            X_d_transform,\n",
    "        )\n",
    "        self.agg: MixtureAggregation\n",
    "\n",
    "    def fingerprint(\n",
    "        self,\n",
    "        bmgs: Iterable[BatchComponentMolGraph | BatchMolGraph],\n",
    "        V_ds: Iterable[Tensor],\n",
    "        X_d: Tensor | None = None,\n",
    "    ) -> Tensor:\n",
    "        H_vs: list[Tensor] = self.message_passing(bmgs, V_ds)\n",
    "        H = self.agg(H_vs, bmgs)\n",
    "        H = self.bn(H)\n",
    "        return H if X_d is None else torch.cat((H, self.X_d_transform(X_d)), 1)\n",
    "\n",
    "    @classmethod\n",
    "    def _load(cls, path, map_location, **submodules):\n",
    "        d = torch.load(path, map_location, weights_only=False)\n",
    "\n",
    "        try:\n",
    "            hparams = d[\"hyper_parameters\"]\n",
    "            state_dict = d[\"state_dict\"]\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"Could not find hyper parameters and/or state dict in {path}.\")\n",
    "\n",
    "        hparams[\"message_passing\"][\"blocks\"] = [\n",
    "            block_hparams.pop(\"cls\")(**block_hparams)\n",
    "            for block_hparams in hparams[\"message_passing\"][\"blocks\"]\n",
    "        ]\n",
    "        graph_agg_hparams = hparams[\"agg\"][\"graph_agg\"]\n",
    "        hparams[\"agg\"][\"graph_agg\"] = graph_agg_hparams.pop(\"cls\")(**graph_agg_hparams)\n",
    "        submodules |= {\n",
    "            key: hparams[key].pop(\"cls\")(**hparams[key])\n",
    "            for key in (\"message_passing\", \"agg\", \"predictor\")\n",
    "            if key not in submodules\n",
    "        }\n",
    "\n",
    "        if not hasattr(submodules[\"predictor\"].criterion, \"_defaults\"):\n",
    "            submodules[\"predictor\"].criterion = submodules[\"predictor\"].criterion.__class__(\n",
    "                task_weights=submodules[\"predictor\"].criterion.task_weights\n",
    "            )\n",
    "\n",
    "        return submodules, state_dict, hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemprop_dir = Path.cwd().parent\n",
    "input_path = (\n",
    "    chemprop_dir / \"tests\" / \"data\" / \"regression\" / \"mol+mol\" / \"mol+mol.csv\"\n",
    ")  # path to your data .csv file containing SMILES strings and target values\n",
    "smiles_columns = [\"smiles\", \"solvent\"]  # name of the column containing SMILES strings\n",
    "target_columns = [\"peakwavs_max\"]  # list of names of the columns containing targets\n",
    "df_input = pd.read_csv(input_path)\n",
    "smiss = df_input.loc[:, smiles_columns].values\n",
    "ys = df_input.loc[:, target_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [[MoleculeDatapoint.from_smi(smis[0], y) for smis, y in zip(smiss, ys)]]\n",
    "all_data += [[ComponentDatapoint.from_smi(smis[0], w_fp=0.1) for smis in smiss]]\n",
    "all_data += [[ComponentDatapoint.from_smi(smis[1], w_fp=0.9) for smis in smiss]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The return type of make_split_indices has changed in v2.1 - see help(make_split_indices)\n"
     ]
    }
   ],
   "source": [
    "component_to_split_by = 0  # index of the component to use for structure based splits\n",
    "mols = [d.mol for d in all_data[component_to_split_by]]\n",
    "train_indices, val_indices, test_indices = make_split_indices(mols, \"random\", (0.8, 0.1, 0.1))\n",
    "train_data, val_data, test_data = split_data_by_indices(\n",
    "    all_data, train_indices, val_indices, test_indices\n",
    ")\n",
    "train_data = train_data[0]\n",
    "val_data = val_data[0]\n",
    "test_data = test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = [\n",
    "    MoleculeDataset(train_data[0]),\n",
    "    ComponentDataset(train_data[1]),\n",
    "    ComponentDataset(train_data[2]),\n",
    "]\n",
    "val_datasets = [\n",
    "    MoleculeDataset(val_data[0]),\n",
    "    ComponentDataset(val_data[1]),\n",
    "    ComponentDataset(val_data[2]),\n",
    "]\n",
    "test_datasets = [\n",
    "    MoleculeDataset(test_data[0]),\n",
    "    ComponentDataset(test_data[1]),\n",
    "    ComponentDataset(test_data[2]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mcdset = MixtureDataset(train_datasets)\n",
    "scaler = train_mcdset.normalize_targets()\n",
    "val_mcdset = MixtureDataset(val_datasets)\n",
    "val_mcdset.normalize_targets(scaler)\n",
    "test_mcdset = MixtureDataset(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_mcdset, batch_size=10, shuffle=True, collate_fn=collate_mixture)\n",
    "val_loader = DataLoader(val_mcdset, batch_size=10, shuffle=False, collate_fn=collate_mixture)\n",
    "test_loader = DataLoader(test_mcdset, batch_size=10, shuffle=False, collate_fn=collate_mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmp = MulticomponentMessagePassing(blocks=[BondMessagePassing()], n_components=3, shared=True)\n",
    "\n",
    "graph_agg = MeanAggregation()\n",
    "mixagg = WeightedSumAggregation(\n",
    "    graph_agg=graph_agg, groups=[[0], [1, 2]], fp_dims=[mcmp.blocks[0].output_dim] * 3\n",
    ")\n",
    "mixagg = ConcatAggregation(\n",
    "    graph_agg=graph_agg, groups=[[0], [1, 2]], fp_dims=[mcmp.blocks[0].output_dim] * 3\n",
    ")\n",
    "\n",
    "output_transform = UnscaleTransform.from_standard_scaler(scaler)\n",
    "ffn = RegressionFFN(input_dim=mixagg.output_dim, output_transform=output_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixtureMPNN(\n",
       "  (message_passing): MulticomponentMessagePassing(\n",
       "    (blocks): ModuleList(\n",
       "      (0-2): 3 x BondMessagePassing(\n",
       "        (W_i): Linear(in_features=86, out_features=300, bias=False)\n",
       "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
       "        (W_o): Linear(in_features=372, out_features=300, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (tau): ReLU()\n",
       "        (V_d_transform): Identity()\n",
       "        (graph_transform): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (agg): ConcatAggregation(\n",
       "    (graph_agg): MeanAggregation()\n",
       "  )\n",
       "  (bn): Identity()\n",
       "  (predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=902, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[1.0]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (X_d_transform): Identity()\n",
       "  (metrics): ModuleList(\n",
       "    (0-1): 2 x MSE(task_weights=[[1.0]])\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmpnn = MixtureMPNN(mcmp, mixagg, ffn)\n",
    "mcmpnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=False,\n",
    "    enable_checkpointing=True,\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/knathan/chemprop/examples/checkpoints exists and is not empty.\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name            | Type                         | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0 | message_passing | MulticomponentMessagePassing | 227 K  | train\n",
      "1 | agg             | ConcatAggregation            | 0      | train\n",
      "2 | bn              | Identity                     | 0      | train\n",
      "3 | predictor       | RegressionFFN                | 271 K  | train\n",
      "4 | X_d_transform   | Identity                     | 0      | train\n",
      "5 | metrics         | ModuleList                   | 0      | train\n",
      "-------------------------------------------------------------------------\n",
      "498 K     Trainable params\n",
      "0         Non-trainable params\n",
      "498 K     Total params\n",
      "1.996     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 8/8 [00:01<00:00,  7.02it/s, train_loss_step=0.0073, val_loss=0.588, train_loss_epoch=0.00598]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 8/8 [00:01<00:00,  6.83it/s, train_loss_step=0.0073, val_loss=0.588, train_loss_epoch=0.00598]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(mcmpnn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 29.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     7638.09228515625      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    7638.09228515625     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.test(mcmpnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 31.32it/s]\n"
     ]
    }
   ],
   "source": [
    "results = trainer.predict(mcmpnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[398.7043],\n",
       "         [650.7003],\n",
       "         [377.3484],\n",
       "         [395.7841],\n",
       "         [389.0737],\n",
       "         [438.4164],\n",
       "         [362.5379],\n",
       "         [378.0801],\n",
       "         [441.8935],\n",
       "         [462.4413]])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[384. ],\n",
       "       [553. ],\n",
       "       [394. ],\n",
       "       [428.2],\n",
       "       [386. ],\n",
       "       [369. ],\n",
       "       [520. ],\n",
       "       [515. ],\n",
       "       [313. ],\n",
       "       [480. ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset.datasets[0].Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

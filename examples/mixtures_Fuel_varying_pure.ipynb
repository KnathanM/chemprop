{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from dataclasses import InitVar, dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Iterable, NamedTuple, Sequence, TypeAlias\n",
    "\n",
    "from lightning import pytorch as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit.Chem import Mol\n",
    "import rdkit.Chem as Chem\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from chemprop.data.collate import BatchMolGraph, collate_batch\n",
    "from chemprop.data.datapoints import MoleculeDatapoint\n",
    "from chemprop.data.datasets import Datum, MoleculeDataset, MulticomponentDataset, ReactionDataset\n",
    "from chemprop.data.molgraph import MolGraph\n",
    "from chemprop.data.splitting import make_split_indices, split_data_by_indices\n",
    "from chemprop.featurizers import Featurizer, SimpleMoleculeMolGraphFeaturizer\n",
    "from chemprop.models import MulticomponentMPNN, multi\n",
    "from chemprop.nn.agg import Aggregation, MeanAggregation\n",
    "from chemprop.nn.hparams import HasHParams\n",
    "from chemprop.nn.message_passing import BondMessagePassing, MessagePassing\n",
    "from chemprop.nn.metrics import ChempropMetric, MSE, RMSE, MAE, R2Score\n",
    "from chemprop.nn.predictors import Predictor, RegressionFFN\n",
    "from chemprop.nn.transforms import ScaleTransform, UnscaleTransform\n",
    "from chemprop.nn.utils import Activation, get_activation_function\n",
    "from lightning.pytorch.core.mixins import HyperparametersMixin\n",
    "from chemprop.conf import DEFAULT_ATOM_FDIM, DEFAULT_BOND_FDIM, DEFAULT_HIDDEN_DIM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first extend the `MolGraph` class to include a global attribute `w_fp` which is the weight of the learned fingerprint of the molecule when averaging the fingerprints of components in the mixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See also chemprop.data.molgraph.MolGraph\n",
    "class ComponentMolGraph(NamedTuple):\n",
    "    V: np.ndarray\n",
    "    E: np.ndarray\n",
    "    edge_index: np.ndarray\n",
    "    rev_edge_index: np.ndarray\n",
    "    w_fp: float = 1.0\n",
    "    \"\"\"the weight of the component's fingerprint when combining components in the mixture\"\"\"\n",
    "\n",
    "\n",
    "# See also chemprop.data.datasets.Datum\n",
    "class ComponentDatum(NamedTuple):\n",
    "    mg: ComponentMolGraph\n",
    "    V_d: np.ndarray | None\n",
    "    x_d: np.ndarray | None\n",
    "    y: np.ndarray | None\n",
    "    weight: float\n",
    "    lt_mask: np.ndarray | None\n",
    "    gt_mask: np.ndarray | None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batched versions of `MolGraph` and `Datum` are created during collating datapoints. These are also extended, as well as the entire batch representing all components in the mixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See also chemprop.data.collate.BatchMolGraph\n",
    "@dataclass(repr=False, eq=False, slots=True)\n",
    "class BatchComponentMolGraph(BatchMolGraph):\n",
    "    mgs: InitVar[Sequence[ComponentMolGraph]]\n",
    "    w_fps: Tensor = field(init=False)\n",
    "    __is_empty: bool = field(init=False)\n",
    "\n",
    "    def __post_init__(self, mgs):    \n",
    "        # super(BatchComponentMolGraph, self).__post_init__(mgs) \n",
    "        self._BatchMolGraph__size = len(mgs)\n",
    "        self.__is_empty = True   \n",
    "        Vs = []\n",
    "        Es = []\n",
    "        edge_indexes = []\n",
    "        rev_edge_indexes = []\n",
    "        batch_indexes = []\n",
    "        w_fps = []\n",
    "\n",
    "        num_nodes = 0\n",
    "        num_edges = 0\n",
    "        for i, mg in enumerate(mgs):\n",
    "            if mg is None:\n",
    "                continue\n",
    "            Vs.append(mg.V)\n",
    "            Es.append(mg.E)\n",
    "            edge_indexes.append(mg.edge_index + num_nodes)\n",
    "            rev_edge_indexes.append(mg.rev_edge_index + num_edges)\n",
    "            batch_indexes.append([i] * len(mg.V))\n",
    "            w_fps.append(mg.w_fp)\n",
    "\n",
    "            num_nodes += mg.V.shape[0]\n",
    "            num_edges += mg.edge_index.shape[1]\n",
    "\n",
    "        self.V = torch.from_numpy(np.concatenate(Vs)).float() if len(Vs) > 0 else None\n",
    "        self.E = torch.from_numpy(np.concatenate(Es)).float() if len(Es) > 0 else None\n",
    "        self.edge_index = torch.from_numpy(np.hstack(edge_indexes)).long() if len(edge_indexes) > 0 else None\n",
    "        self.rev_edge_index = torch.from_numpy(np.concatenate(rev_edge_indexes)).long() if len(rev_edge_indexes) > 0 else None\n",
    "        self.batch = torch.tensor(np.concatenate(batch_indexes)).long() if len(batch_indexes) > 0 else None\n",
    "        self.w_fps = torch.from_numpy(np.array(w_fps)).float() if len(w_fps) > 0 else None\n",
    "\n",
    "        if len(Vs) > 0:\n",
    "            self.__is_empty = False\n",
    "\n",
    "    def to(self, device: str | torch.device):\n",
    "        if not self.is_empty():\n",
    "            super(BatchComponentMolGraph, self).to(device)\n",
    "            self.w_fps = self.w_fps.to(device)\n",
    "\n",
    "    def is_empty(self) -> bool:\n",
    "        \"\"\"whether any :class:`MolGraph`\\s are stored in this batch\"\"\"\n",
    "        return self.__is_empty\n",
    "\n",
    "\n",
    "# See also chemprop.data.collate.TrainingBatch\n",
    "class BatchComponentDatum(NamedTuple):\n",
    "    bmg: BatchComponentMolGraph\n",
    "    V_d: Tensor | None\n",
    "    X_d: Tensor | None\n",
    "    Y: Tensor | None\n",
    "    w: Tensor\n",
    "    lt_mask: Tensor | None\n",
    "    gt_mask: Tensor | None\n",
    "\n",
    "\n",
    "# See also chemprop.data.collate.MulticomponentTrainingBatch\n",
    "class MixtureBatch(NamedTuple):\n",
    "    bmgs: list[BatchMolGraph | BatchComponentMolGraph]\n",
    "    V_ds: list[Tensor | None]\n",
    "    X_d: Tensor | None\n",
    "    Y: Tensor | None\n",
    "    w: Tensor\n",
    "    lt_mask: Tensor | None\n",
    "    gt_mask: Tensor | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See also chemprop.data.collate.collate_batch\n",
    "def collate_component(batch: Iterable[Datum]) -> BatchComponentDatum:\n",
    "    mgs, V_ds, x_ds, ys, weights, lt_masks, gt_masks = zip(*batch)\n",
    "\n",
    "    return BatchComponentDatum(\n",
    "        BatchComponentMolGraph(mgs),\n",
    "        None if V_ds[0] is None else torch.from_numpy(np.concatenate(V_ds)).float(),\n",
    "        None if x_ds[0] is None else torch.from_numpy(np.array(x_ds)).float(),\n",
    "        None if ys[0] is None else torch.from_numpy(np.array(ys)).float(),\n",
    "        torch.tensor(weights, dtype=torch.float).unsqueeze(1),\n",
    "        None if lt_masks[0] is None else torch.from_numpy(np.array(lt_masks)),\n",
    "        None if gt_masks[0] is None else torch.from_numpy(np.array(gt_masks)),\n",
    "    )\n",
    "\n",
    "\n",
    "# See also chemprop.data.collate.collate_multicomponent\n",
    "def collate_mixture(batches: Iterable[Iterable[ComponentDatum | Datum]]) -> MixtureBatch:\n",
    "    tbs = [\n",
    "        collate_batch(batch) if isinstance(batch[0], Datum) else collate_component(batch)\n",
    "        for batch in zip(*batches)\n",
    "    ]\n",
    "\n",
    "    return MixtureBatch(\n",
    "        [tb.bmg for tb in tbs],\n",
    "        [tb.V_d for tb in tbs],\n",
    "        tbs[0].X_d,\n",
    "        tbs[0].Y,\n",
    "        tbs[0].w,\n",
    "        tbs[0].lt_mask,\n",
    "        tbs[0].gt_mask,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ComponentDatapoint(MoleculeDatapoint):\n",
    "    w_fp: np.ndarray | None = None\n",
    "    \"\"\"the weight of the molecule's learned fingerprint when averaging in the mixture\"\"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ComponentDataset(MoleculeDataset, Dataset[ComponentMolGraph]):\n",
    "    data: list[ComponentDatapoint]\n",
    "\n",
    "    @property\n",
    "    def w_fps(self) -> np.ndarray:\n",
    "        return np.array([d.w_fp for d in self.data])\n",
    "\n",
    "    def __getitem__(self, idx: int) -> ComponentDatum:\n",
    "        d = self.data[idx]\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        if d.mol:\n",
    "            mg = self.mg_cache[idx] #if d.mol else [np.array(torch.zeros(1,1)), np.array(torch.zeros(2,1)), np.array(torch.zeros(1,1)), np.array(torch.zeros(1,1))] # account for varying number of components in mixtures, i.e., some mixtures contain less components which are handled as NoneType\n",
    "            mg = ComponentMolGraph(w_fp=d.w_fp, *mg)\n",
    "        else:\n",
    "            mg = None\n",
    "\n",
    "        return ComponentDatum(\n",
    "            mg, self.V_ds[idx], self.X_d[idx], self.Y[idx], d.weight, d.lt_mask, d.gt_mask\n",
    "        )\n",
    "\n",
    "\n",
    "@dataclass(repr=False, eq=False)\n",
    "class MixtureDataset(MulticomponentDataset):\n",
    "    datasets: list[MoleculeDataset | ReactionDataset | ComponentDataset]\n",
    "\n",
    "    def __getitem__(self, idx: int) -> list[ComponentDatum | Datum]:\n",
    "        return [dset[idx] for dset in self.datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticomponentMessagePassing(nn.Module, HasHParams):\n",
    "    \"\"\"A `MulticomponentMessagePassing` performs message-passing on each individual input in a\n",
    "    multicomponent input then concatenates the representation of each input to construct a\n",
    "    global representation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    blocks : Sequence[MessagePassing]\n",
    "        the invidual message-passing blocks for each input\n",
    "    n_components : int\n",
    "        the number of components in each input\n",
    "    shared : bool, default=False\n",
    "        whether one block will be shared among all components in an input. If not, a separate\n",
    "        block will be learned for each component.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        blocks: Sequence[MessagePassing], \n",
    "        groups: Sequence[Sequence[int]], \n",
    "        shared: bool = False,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.hparams = {\n",
    "            \"cls\": self.__class__,\n",
    "            \"blocks\": [block.hparams for block in blocks],\n",
    "            \"groups\": groups,\n",
    "            \"shared\": shared,\n",
    "        }\n",
    "\n",
    "        if len(blocks) == 0:\n",
    "            raise ValueError(\"arg 'blocks' was empty!\")\n",
    "        if groups is None:\n",
    "            raise ValueError(\"arg 'groups' was empty!\")\n",
    "\n",
    "        if shared:\n",
    "            if len(blocks) > 1:\n",
    "                logger.warning(\n",
    "                    \"More than 1 block was supplied but 'shared' was True! Using only the 0th block...\"\n",
    "                )\n",
    "            if len(groups) != sum(len(g) if isinstance(g, list) else 1 for g in groups):\n",
    "                logger.warning(\n",
    "                    \"Different groups were supplied but 'shared' was True! Using only the 0th block for all groups...\"\n",
    "                )\n",
    "        else:\n",
    "            if len(blocks) != len(groups):\n",
    "                raise ValueError(\n",
    "                    \"arg 'len(groups)' must be equal to `len(blocks)` if 'shared' is False!\"\n",
    "                    f\"got: {len(groups)} and {len(blocks)}, respectively.\"\n",
    "                )\n",
    "\n",
    "        self.groups = groups\n",
    "        self.shared = shared\n",
    "        self.blocks = nn.ModuleList()\n",
    "        if shared:\n",
    "            self.blocks.extend([blocks[0]] * len(groups))\n",
    "        else:\n",
    "            b_idx = 0\n",
    "            for g_idx, g in enumerate(groups):\n",
    "                self.blocks.extend([blocks[g_idx]] * len(g))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.blocks)\n",
    "\n",
    "    @property\n",
    "    def output_dim(self) -> int:\n",
    "        d_o = sum(block.output_dim for block in self.blocks)\n",
    "\n",
    "        return d_o\n",
    "\n",
    "    def forward(self, bmgs: Iterable[BatchMolGraph], V_ds: Iterable[Tensor | None]) -> list[Tensor]:\n",
    "        \"\"\"Encode the multicomponent inputs\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bmgs : Iterable[BatchMolGraph]\n",
    "        V_ds : Iterable[Tensor | None]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[Tensor]\n",
    "            a list of tensors of shape `V x d_i` containing the respective encodings of the `i`\\th\n",
    "            component, where `d_i` is the output dimension of the `i`\\th encoder\n",
    "        \"\"\"\n",
    "        if V_ds is None:\n",
    "            return [block(bmg) if not bmg.is_empty() else None for block, bmg in zip(self.blocks, bmgs)]\n",
    "        else:\n",
    "            return [block(bmg, V_d) if not bmg.is_empty() else None for block, bmg, V_d in zip(self.blocks, bmgs, V_ds)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureMessagePassing(nn.Module, HyperparametersMixin):\n",
    "    r\"\"\"A :class:`MixtureMessagePassing` encodes a batch of mixtures by passing messages along\n",
    "    molecules constructing a fully connected graph to model intermolecular interactions.\n",
    "\n",
    "    It implements the following operation:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        h_v^{(0)} &= \\tau \\left( \\mathbf{W}_i(x_v) \\right) \\\\\n",
    "        m_v^{(t)} &= \\sum_{u \\in \\mathcal{w \\in V \\setminu v} h_w^{(t-1)} \\\\\n",
    "        h_v^{(T)} &= \\tau\\left(h_v^{(0)} + \\mathbf{W}_h m_v^{(t-1)}\\right) \\\\\n",
    "\n",
    "    where :math:`\\tau` is the activation function; :math:`\\mathbf{W}_i`, :math:`\\mathbf{W}_h` are learned weight matrices; :math:`e_{vw}` is the feature vector of the\n",
    "    bond between molecules :math:`v` and :math:`w`; :math:`x_v` is the feature vector of molecule :math:`v`;\n",
    "    :math:`h_v^{(t)}` is the hidden representation of atom :math:`v` at iteration :math:`t`;\n",
    "    :math:`m_v^{(t)}` is the message received by atom :math:`v` at iteration :math:`t`; and\n",
    "    :math:`t \\in \\{1, \\dots, T\\}` is the number of message passing iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_v: int = DEFAULT_HIDDEN_DIM,\n",
    "        d_e: int | None = None,\n",
    "        d_h: int = DEFAULT_HIDDEN_DIM,\n",
    "        d_vd: int | None = None,\n",
    "        bias: bool = False,\n",
    "        depth: int = 1,\n",
    "        activation: str | Activation = Activation.RELU,\n",
    "    ):        \n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.hparams[\"cls\"] = self.__class__\n",
    "\n",
    "        self.depth = depth\n",
    "        self.tau = get_activation_function(activation)\n",
    "        \n",
    "        self.W_i = nn.Linear(d_v, d_h, bias)\n",
    "        self.W_h = nn.Linear(d_h, d_h, bias) # TODO consider E\n",
    "        self.W_o = None\n",
    "        self.W_d = None\n",
    "\n",
    "    def initialize(self, V: Tensor) -> Tensor:\n",
    "        return self.W_i(V)\n",
    "\n",
    "    def message(self, H: Tensor):\n",
    "        # assume fully connected graph, TODO\n",
    "        H = torch.transpose(H, 0, 1) # b x n x d\n",
    "        M_t = H.unsqueeze(2).expand(-1, -1, H.size(1), -1) # b x n x n x d\n",
    "        M_t = self.W_h(M_t)\n",
    "        mask = ~torch.eye(H.size(1), dtype=bool, device=H.device).unsqueeze(0) # exclude self-loops (n x n)\n",
    "        M_t = (M_t * mask.unsqueeze(-1)).sum(dim=1) # b x n x d\n",
    "        M_t = torch.transpose(M_t, 0, 1) # n x b x d\n",
    "        return M_t\n",
    "\n",
    "    def update(self, M_t: Tensor, H_0: Tensor):\n",
    "        H_t = self.tau(H_0 + M_t)\n",
    "        return H_t\n",
    "\n",
    "    def finalize(self, H_t: Tensor):\n",
    "        return [h for h in H_t]\n",
    "\n",
    "    def forward(self, V: list[Tensor]):\n",
    "        H_0 = self.initialize(torch.stack(V))\n",
    "        H = self.tau(H_0)\n",
    "        for _ in range(self.depth):\n",
    "            M = self.message(H)\n",
    "            H = self.update(M, H_0)\n",
    "\n",
    "        return self.finalize(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureAggregation(nn.Module, HasHParams):\n",
    "    output_dim: int\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        graph_agg: Aggregation, \n",
    "        groups: Sequence[Sequence[int]], \n",
    "        fp_dims: Sequence[int], \n",
    "        mixmp: MixtureMessagePassing | None, \n",
    "        *args, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hparams = {\n",
    "            \"cls\": self.__class__,\n",
    "            \"groups\": groups,\n",
    "            \"fp_dims\": fp_dims,\n",
    "        }\n",
    "        self.graph_agg = graph_agg\n",
    "        self.groups = groups\n",
    "        self.fp_dims = fp_dims\n",
    "        self.mixmp = mixmp\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(\n",
    "        self, Hs: list[Tensor], bmgs: list[BatchComponentMolGraph | BatchMolGraph]\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Aggregate component representations into a mixture representation\"\"\"\n",
    "\n",
    "    def mol_forward(\n",
    "        self, H_vs: list[Tensor], bmgs: list[BatchComponentMolGraph | BatchMolGraph]\n",
    "    ) -> tuple[list[Tensor], list[Tensor], list[Tensor]]:\n",
    "        # Hs: n x b x d (but not each mixture has n components, so n x b can be incomplete, hence we need to synthetically adapt the sizes)\n",
    "        Hs, w_fps, Hs_batch = zip(*[(self.graph_agg(H_v, torch.unique(bmg.batch, return_inverse=True)[1]), bmg.w_fps, torch.unique(bmg.batch)) if (isinstance(bmg, BatchComponentMolGraph) and (bmg.batch is not None)) else (self.graph_agg(H_v, torch.unique(bmg.batch, return_inverse=True)[1]), None, torch.unique(bmg.batch)) if (bmg.batch is not None) else (None, None, None) for H_v, bmg in zip(H_vs, bmgs)])\n",
    "        Hs, w_fps, Hs_batch =  list(Hs), list(w_fps), list(Hs_batch)\n",
    "        return Hs, w_fps, Hs_batch\n",
    "\n",
    "    def complete_sparse_batch(\n",
    "        self, Hs: list[Tensor], w_fps: list[Tensor], Hs_batch: list[Tensor]\n",
    "    ) -> tuple[list[Tensor], list[Tensor], list[Tensor]]:\n",
    "        # make Hs and w_fps the same size wrt n x b by adding zero-values/tensors\n",
    "        Hs = self._complete_sparse_tensorlist(Hs, Hs_batch, self.fp_dims)\n",
    "        if not all(f is None for f in w_fps):\n",
    "            w_fps = self._complete_sparse_tensorlist(w_fps, Hs_batch, [None for _ in range(len(Hs_batch))])\n",
    "        return Hs, w_fps, Hs_batch\n",
    "\n",
    "    def _complete_sparse_tensorlist(\n",
    "        self, Hs: list[Tensor], Hs_batch: list[Tensor], dim: list[int]\n",
    "    ) -> list[Tensor]:\n",
    "        #dim = max(H_b.a)\n",
    "        batch_size = max(H_b.max().item() for H_b in Hs_batch if not (H_b is None))\n",
    "        device = [H.device for H in Hs if not (H is None)][0] # workaround, TODO\n",
    "        compl_Hs = []\n",
    "        for n_idx, (n_H, n_H_batch) in enumerate(zip(Hs, Hs_batch)):\n",
    "            if dim[n_idx]:\n",
    "                compl_H = torch.zeros((batch_size+1, dim[n_idx]), dtype=torch.float32, device=device)\n",
    "            else:\n",
    "                compl_H = torch.zeros((batch_size+1), dtype=torch.float32, device=device)\n",
    "            if (n_H is not None) and (n_H_batch is not None):\n",
    "                compl_H[n_H_batch] = n_H\n",
    "            compl_Hs.append(compl_H)\n",
    "        return compl_Hs\n",
    "\n",
    "class WeightedSumAggregation(MixtureAggregation):\n",
    "    @property\n",
    "    def output_dim(self) -> int:\n",
    "        return sum(self.fp_dims[group[0]] for group in self.groups)\n",
    "\n",
    "    def forward(\n",
    "        self, H_vs: list[Tensor], bmgs: list[BatchComponentMolGraph | BatchMolGraph]\n",
    "    ) -> Tensor:\n",
    "        Hs, w_fps, Hs_batch = self.mol_forward(H_vs, bmgs)\n",
    "        Hs, w_fps, Hs_batch = self.complete_sparse_batch(Hs, w_fps, Hs_batch)\n",
    "\n",
    "        if not (self.mixmp is None):\n",
    "            Hs = self.mixmp(Hs)\n",
    "\n",
    "        combined_Hs = []\n",
    "        for group in self.groups:\n",
    "            if len(group) == 1:\n",
    "                combined_Hs.append(Hs[group[0]])\n",
    "                continue\n",
    "            group_Hs = torch.stack([Hs[idx] for idx in group])  # n x b x d\n",
    "            #import pdb\n",
    "            #pdb.set_trace()\n",
    "            group_w_fps = torch.stack([w_fps[idx] for idx in group])  # n x b\n",
    "            #pdb.set_trace()\n",
    "            # n: num. components in group, b: num. comp. in batch, d: output dim of message passing\n",
    "            combined_H = torch.einsum(\"nb,nbd->bd\", group_w_fps, group_Hs)\n",
    "            combined_Hs.append(combined_H)\n",
    "        #pdb.set_trace()\n",
    "        return torch.cat(combined_Hs, 1)\n",
    "\n",
    "class ConcatAggregation(MixtureAggregation):\n",
    "    @property\n",
    "    def components_in_mixture(self) -> set[int]:\n",
    "        return {idx for group in self.groups if len(group) > 1 for idx in group}\n",
    "\n",
    "    @property\n",
    "    def output_dim(self) -> int:\n",
    "        return sum(self.fp_dims) + len(self.components_in_mixture)\n",
    "\n",
    "    def forward(\n",
    "        self, H_vs: list[Tensor], bmgs: list[BatchComponentMolGraph | BatchMolGraph]\n",
    "    ) -> Tensor:\n",
    "        Hs, w_fps, Hs_batch = self.mol_forward(H_vs, bmgs)\n",
    "        Hs, w_fps, Hs_batch = self.complete_sparse_batch(Hs, w_fps, Hs_batch)\n",
    "\n",
    "        if not (self.mixmp is None):\n",
    "            Hs = self.mixmp(Hs)\n",
    "\n",
    "        w_fps = torch.stack([w_fps[idx] for idx in self.components_in_mixture], dim=1)\n",
    "        return torch.cat(Hs + [w_fps], 1)\n",
    "\n",
    "class DeepsetsAggregation(MixtureAggregation):\n",
    "    r\"\"\"Deep sets aggregation of the graph-level representation:\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf h = \\mathrm{MLP_{g}}(\\sum_{c \\in C} \\mathrm{MLP_{l}}(\\mathbf h_c))\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, graph_agg: Aggregation, groups: Sequence[Sequence[int]], fp_dims: Sequence[int], \n",
    "        mixmp: MixtureMessagePassing | None, *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(graph_agg, groups, fp_dims, mixmp, *args, **kwargs)\n",
    "        \n",
    "        self.MLPs_local = nn.ModuleList([])\n",
    "        self.MLPs_global = nn.ModuleList([])\n",
    "        for group in groups:\n",
    "            # TODO: allow to set hparams for MLP by kwargs (e.g., hidden_dim, n_layers)\n",
    "            hidden_dim = self.fp_dims[group[0]]\n",
    "            self.MLPs_local.append(\n",
    "                nn.Sequential(\n",
    "                nn.Linear(self.fp_dims[group[0]], hidden_dim, bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim, bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, self.fp_dims[group[0]], bias=False),\n",
    "                )\n",
    "            )\n",
    "            self.MLPs_global.append(\n",
    "                nn.Sequential(\n",
    "                nn.Linear(self.fp_dims[group[0]], hidden_dim, bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim, bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, self.fp_dims[group[0]], bias=False),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def output_dim(self) -> int:\n",
    "        return sum(self.fp_dims[group[0]] for group in self.groups)\n",
    "\n",
    "    def forward(\n",
    "        self, H_vs: list[Tensor], bmgs: list[BatchComponentMolGraph | BatchMolGraph]\n",
    "    ) -> Tensor:\n",
    "        Hs, w_fps, Hs_batch = self.mol_forward(H_vs, bmgs)\n",
    "        Hs, w_fps, Hs_batch = self.complete_sparse_batch(Hs, w_fps, Hs_batch)\n",
    "        \n",
    "        if not (self.mixmp is None):\n",
    "            Hs = self.mixmp(Hs)\n",
    "\n",
    "        combined_Hs = []\n",
    "        for g_idx, group in enumerate(self.groups):\n",
    "            # use only global MLP if group only has one component, as local MLP would just be nested into global MLP\n",
    "            if len(group) == 1:\n",
    "                combined_Hs.append(self.MLPs_global[g_idx](Hs[group[0]]))\n",
    "                continue\n",
    "            group_w_Hs = torch.stack([self.MLPs_local[g_idx](w_fps[idx].unsqueeze(1) * Hs[idx]) for idx in group])  # n x b x d\n",
    "            combined_H = torch.sum(group_w_Hs, dim=0)\n",
    "            combined_Hs.append(self.MLPs_global[g_idx](combined_H))\n",
    "        return torch.cat(combined_Hs, 1)\n",
    "\n",
    "class AttentiveAggregation(MixtureAggregation):\n",
    "    r\"\"\"Attentive aggregation of the graph-level representation:\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf h = \\sum_{c \\in C} \\alpha_c \\mathbf h_c\n",
    "\n",
    "        \\alpha_c = \\mathrm{softmax}(\\mathbf h_c)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, graph_agg: Aggregation, groups: Sequence[Sequence[int]], fp_dims: Sequence[int], \n",
    "        mixmp: MixtureMessagePassing | None, *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(graph_agg, groups, fp_dims, mixmp, *args, **kwargs)\n",
    "        \n",
    "        self.Ws_a = nn.ModuleList([\n",
    "            nn.Linear(self.fp_dims[group[0]], 1, bias=False) for group in groups\n",
    "            ])\n",
    "\n",
    "    @property\n",
    "    def output_dim(self) -> int:\n",
    "        return sum(self.fp_dims[group[0]] for group in self.groups)\n",
    "\n",
    "    def forward(\n",
    "        self, H_vs: list[Tensor], bmgs: list[BatchComponentMolGraph | BatchMolGraph]\n",
    "    ) -> Tensor:\n",
    "        Hs, w_fps, Hs_batch = self.mol_forward(H_vs, bmgs)\n",
    "        Hs, w_fps, Hs_batch = self.complete_sparse_batch(Hs, w_fps, Hs_batch)\n",
    "\n",
    "        if not (self.mixmp is None):\n",
    "            Hs = self.mixmp(Hs)\n",
    "\n",
    "        combined_Hs = []\n",
    "        for g_idx, group in enumerate(self.groups):\n",
    "            if len(group) == 1:\n",
    "                combined_Hs.append((Hs[group[0]]))\n",
    "                continue\n",
    "            w_Hs = torch.stack([w_fps[idx].unsqueeze(1) * Hs[idx] for idx in group])  # n x b x d\n",
    "            attention_logits = self.Ws_a[g_idx](w_Hs).exp().squeeze(2) # n x b\n",
    "            # Ignore logits that correspond to completed zero-tensors due to missing components\n",
    "            # Create a mask tensor\n",
    "            mask = torch.zeros_like(attention_logits, dtype=torch.bool)\n",
    "            # Fill the mask tensor based on index \n",
    "            for tmp_i, idx in enumerate(group):\n",
    "                indices = Hs_batch[idx]\n",
    "                if indices is not None:\n",
    "                    mask[tmp_i, indices] = True\n",
    "            # Apply the mask to the original tensor\n",
    "            attention_logits = attention_logits * mask\n",
    "            #attention_logits = torch.stack(self.complete_sparse_batch([a.unsqueeze(0) for a in attention_logits], Hs_batch, [None for _ in attention_logits]))\n",
    "            Z = torch.sum(attention_logits, dim=0, keepdim=True)\n",
    "            alphas = attention_logits / Z\n",
    "            combined_H = torch.sum(alphas.unsqueeze(-1) * w_Hs, dim=0)\n",
    "            #import pdb\n",
    "            combined_Hs.append(combined_H)\n",
    "        return torch.cat(combined_Hs, 1)\n",
    "\n",
    "class Set2SetAggregation(MixtureAggregation):\n",
    "    r\"\"\"Set2Set aggregation of the graph-level representation:\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{q}_t &= \\mathrm{LSTM}(\\mathbf{q}^{*}_{t-1})\n",
    "\n",
    "        \\alpha_{c,t} &= \\mathrm{softmax}(\\mathbf{h}_c \\cdot \\mathbf{q}_t)\n",
    "\n",
    "        \\mathbf{r}_t &= \\sum_{c=1}^C \\alpha_{c,t} \\mathbf{h}_c\n",
    "\n",
    "        \\mathbf{q}^{*}_t &= \\mathbf{q}_t \\, \\Vert \\, \\mathbf{r}_t,\n",
    "\n",
    "    where :math:`\\mathbf{q}^{*}_T` defines the output of the layer with twice\n",
    "    the dimensionality as the input.\n",
    "    \n",
    "    Note: This implementation follows PyTorch Geometric (cf. https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/aggr/set2set.html#Set2Set) and is based on `\"Order Matters: Sequence to sequence for\n",
    "    Sets\" <https://arxiv.org/abs/1511.06391>`_ paper.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, graph_agg: Aggregation, groups: Sequence[Sequence[int]], fp_dims: Sequence[int], \n",
    "        mixmp: MixtureMessagePassing | None, *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(graph_agg, groups, fp_dims, mixmp, *args, **kwargs)\n",
    "        \n",
    "        # TODO: allow to set hparams for Set2Set by kwargs (e.g., processing steps)\n",
    "        self.processing_steps = 3\n",
    "        self.lstms = nn.ModuleList([])\n",
    "        for group in groups:\n",
    "            in_channels = self.fp_dims[group[0]]\n",
    "            out_channels = self.fp_dims[group[0]] * 2\n",
    "            self.lstms.append(\n",
    "                torch.nn.LSTM(out_channels, in_channels, **kwargs)\n",
    "                )\n",
    "\n",
    "    @property\n",
    "    def output_dim(self) -> int:\n",
    "        return sum(self.fp_dims[group[0]] * 2 if len(group) > 1 else self.fp_dims[group[0]] for group in self.groups)\n",
    "\n",
    "    def forward(\n",
    "        self, H_vs: list[Tensor], bmgs: list[BatchComponentMolGraph | BatchMolGraph]\n",
    "    ) -> Tensor:\n",
    "        Hs, w_fps, Hs_batch = self.mol_forward(H_vs, bmgs)\n",
    "        Hs, w_fps, Hs_batch = self.complete_sparse_batch(Hs, w_fps, Hs_batch)\n",
    "\n",
    "        if not (self.mixmp is None):\n",
    "            Hs = self.mixmp(Hs)\n",
    "            \n",
    "        combined_Hs = []\n",
    "        for g_idx, group in enumerate(self.groups):\n",
    "            if len(group) == 1:\n",
    "                combined_Hs.append((Hs[group[0]]))\n",
    "                continue\n",
    "            \n",
    "            w_Hs = torch.stack([w_fps[idx].unsqueeze(1) * Hs[idx] for idx in group]) \n",
    "            w_Hs = torch.transpose(w_Hs, 0, 1) # b x n x d\n",
    "            b_dim = w_Hs.size(0)\n",
    "            d_dim = w_Hs.size(-1)\n",
    "\n",
    "            h = (w_Hs.new_zeros((self.lstms[g_idx].num_layers, b_dim, d_dim)),\n",
    "                w_Hs.new_zeros((self.lstms[g_idx].num_layers, b_dim, d_dim)))\n",
    "            q_star = w_Hs.new_zeros(b_dim, d_dim * 2)\n",
    "\n",
    "            for _ in range(self.processing_steps):\n",
    "                q, h = self.lstms[g_idx](q_star.unsqueeze(0), h)\n",
    "\n",
    "                q = q.squeeze(0) # b x d\n",
    "                e = torch.sum(w_Hs * q.unsqueeze(1), dim=2) # b x n\n",
    "                \n",
    "                #a = torch.softmax(e, dim=1) # b x n, old version\n",
    "\n",
    "                attention_logits = e.exp() #.squeeze(2) # b x n\n",
    "\n",
    "                # Ignore logits that correspond to completed zero-tensors due to missing components\n",
    "                # Create a mask tensor\n",
    "                mask = torch.zeros_like(e, dtype=torch.bool)\n",
    "                # Fill the mask tensor based on index tensors\n",
    "                for tmp_i, idx in enumerate(group):\n",
    "                    indices = Hs_batch[idx]\n",
    "                    if indices is not None:\n",
    "                        mask[indices, tmp_i] = True\n",
    "                # Apply the mask to the original tensor\n",
    "                attention_logits = attention_logits * mask\n",
    "                Z = torch.sum(attention_logits, dim=1, keepdim=True)\n",
    "                alphas = attention_logits / Z\n",
    "                r = torch.sum(w_Hs * alphas.unsqueeze(2), dim=1) # b x d\n",
    "                q_star = torch.cat([q, r], dim=1) # b x 2*d\n",
    "\n",
    "            combined_Hs.append(q_star)\n",
    "        return torch.cat(combined_Hs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureMPNN(MulticomponentMPNN):\n",
    "    def __init__(\n",
    "        self,\n",
    "        message_passing: MulticomponentMessagePassing,\n",
    "        agg: Aggregation,\n",
    "        predictor: Predictor,\n",
    "        mix_mpn: MixtureMessagePassing | None = None,\n",
    "        batch_norm: bool = False,\n",
    "        metrics: Iterable[ChempropMetric] | None = None,\n",
    "        warmup_epochs: int = 2,\n",
    "        init_lr: float = 1e-4,\n",
    "        max_lr: float = 1e-3,\n",
    "        final_lr: float = 1e-4,\n",
    "        X_d_transform: ScaleTransform | None = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            message_passing,\n",
    "            agg,\n",
    "            predictor,\n",
    "            batch_norm,\n",
    "            metrics,\n",
    "            warmup_epochs,\n",
    "            init_lr,\n",
    "            max_lr,\n",
    "            final_lr,\n",
    "            X_d_transform,\n",
    "        )\n",
    "        self.agg: MixtureAggregation\n",
    "\n",
    "    def fingerprint(\n",
    "        self,\n",
    "        bmgs: Iterable[BatchComponentMolGraph | BatchMolGraph],\n",
    "        V_ds: Iterable[Tensor],\n",
    "        X_d: Tensor | None = None,\n",
    "    ) -> Tensor:\n",
    "        H_vs: list[Tensor] = self.message_passing(bmgs, V_ds)\n",
    "        H = self.agg(H_vs, bmgs)\n",
    "        H = self.bn(H)\n",
    "        return H if X_d is None else torch.cat((H, X_d), 1)\n",
    "\n",
    "    @classmethod\n",
    "    def _load(cls, path, map_location, **submodules):\n",
    "        d = torch.load(path, map_location, weights_only=False)\n",
    "\n",
    "        try:\n",
    "            hparams = d[\"hyper_parameters\"]\n",
    "            state_dict = d[\"state_dict\"]\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"Could not find hyper parameters and/or state dict in {path}.\")\n",
    "\n",
    "        hparams[\"message_passing\"][\"blocks\"] = [\n",
    "            block_hparams.pop(\"cls\")(**block_hparams)\n",
    "            for block_hparams in hparams[\"message_passing\"][\"blocks\"]\n",
    "        ]\n",
    "        graph_agg_hparams = hparams[\"agg\"][\"graph_agg\"]\n",
    "        hparams[\"agg\"][\"graph_agg\"] = graph_agg_hparams.pop(\"cls\")(**graph_agg_hparams)\n",
    "        mixmp_hparams = hparams[\"agg\"][\"mixmp\"]\n",
    "        hparams[\"agg\"][\"mixmp\"] = mixmp_hparams.pop(\"cls\")(**mixmp_hparams)\n",
    "        submodules |= {\n",
    "            key: hparams[key].pop(\"cls\")(**hparams[key])\n",
    "            for key in (\"message_passing\", \"agg\", \"predictor\")\n",
    "            if key not in submodules\n",
    "        }\n",
    "\n",
    "        if not hasattr(submodules[\"predictor\"].criterion, \"_defaults\"):\n",
    "            submodules[\"predictor\"].criterion = submodules[\"predictor\"].criterion.__class__(\n",
    "                task_weights=submodules[\"predictor\"].criterion.task_weights\n",
    "            )\n",
    "\n",
    "        return submodules, state_dict, hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263, 3)\n",
      "(263, 9)\n"
     ]
    }
   ],
   "source": [
    "chemprop_dir = Path.cwd().parent\n",
    "input_path_pure = (\n",
    "    chemprop_dir / \"examples\" / \"data\" / \"viscosity_pure.csv\" \n",
    ") \n",
    "input_path_train = (\n",
    "    chemprop_dir / \"examples\" / \"data\" / \"viscosity_train.csv\" \n",
    ")  # path to your data .csv file containing SMILES strings and target values\n",
    "input_path_test = (\n",
    "    chemprop_dir / \"examples\" / \"data\" / \"viscosity_test.csv\" \n",
    ") \n",
    "smiles_columns = [\"fuel1 inchi\", \"fuel2 inchi\", \"fuel3 inchi\", \"fuel4 inchi\"]  # name of the column containing SMILES strings\n",
    "frac_columns = [\"molar fraction fuel 1\", \"molar fraction fuel 2\", \"molar fraction fuel 3\"]\n",
    "target_columns = [\"Experimental value (from literature)\"]  # list of names of the columns containing targets\n",
    "df_input_pure = pd.read_csv(input_path_pure, sep=\";\")\n",
    "frac_columns.append(\"molar fraction fuel 4\")\n",
    "df_input_pure[frac_columns[-1]] = np.nan\n",
    "print(df_input_pure.shape)\n",
    "df_input_train = pd.read_csv(input_path_train, sep=\";\")\n",
    "df_input_test = pd.read_csv(input_path_test, sep=\";\")\n",
    "df_input_mix = pd.concat([df_input_train, df_input_test], ignore_index=True)\n",
    "df_input_mix[frac_columns[-1]] = np.nan\n",
    "df_input_mix.loc[:, smiles_columns] = df_input_mix.loc[:, smiles_columns].apply(lambda col: col.apply(lambda x: Chem.MolToSmiles(Chem.MolFromInchi(x)) if x is not np.nan else None)) \n",
    "df_input_pure.loc[:, smiles_columns[0]] = df_input_pure.loc[:, smiles_columns[0]].apply(lambda x: Chem.MolToSmiles(Chem.MolFromInchi(x)) if x is not np.nan else None) \n",
    "\n",
    "for sc in smiles_columns[1:]:\n",
    "    df_input_pure[sc] = None\n",
    "\n",
    "for fc_idx, fc in enumerate(frac_columns):\n",
    "    if fc_idx == 0:\n",
    "        df_input_pure[fc] = 1.0\n",
    "    else:\n",
    "        df_input_pure[fc] = np.nan\n",
    "\n",
    "def fill_zero_fracs(df, frac_columns):\n",
    "    fracs = df.loc[:, frac_columns].values\n",
    "    # calculate molar fractions for all included fuels\n",
    "    for frac_idx, frac in enumerate(fracs):\n",
    "        f_counter = 0\n",
    "        for f_i, f in enumerate(frac):\n",
    "            if np.isnan(f):\n",
    "                fracs[frac_idx][f_i] = 1 - np.sum(np.array([float(frac[c]) for c in range(f_counter)]))\n",
    "            f_counter += 1\n",
    "    return fracs\n",
    "\n",
    "df_input_mix[frac_columns] = fill_zero_fracs(df_input_mix, frac_columns)\n",
    "df_input_pure[frac_columns] = fill_zero_fracs(df_input_pure, frac_columns)\n",
    "\n",
    "df_input_mix.loc[:, target_columns] = df_input_mix.loc[:, target_columns].apply(lambda x: np.log(x)).values.astype(float)\n",
    "df_input_pure.loc[:, target_columns] = df_input_pure.loc[:, target_columns].apply(lambda x: np.log(x)).values.astype(float)\n",
    "print(df_input_pure.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_from_linear_mixing_rule(comp_dict, df_pure_comp, target_column, verbose=False):\n",
    "    pure_comp_props = {}\n",
    "    for c_name, comp in comp_dict[\"smis\"].items(): \n",
    "        if comp[\"name\"] is None: continue\n",
    "        smi_c = smiles_columns[0]\n",
    "        smi = comp[\"name\"]\n",
    "        pure_comp_cond = (df_pure_comp[smi_c] == smi)\n",
    "        if verbose: \n",
    "            print(f\"Pure comp. combination exists: {pure_comp_cond.any()}\")\n",
    "        if not pure_comp_cond.any(): \n",
    "            return np.nan\n",
    "        comp_dict[\"smis\"][c_name][\"prop\"] = df_pure_comp[pure_comp_cond][target_column].values[0]\n",
    "    mix_prop = sum([comp[\"frac\"] * comp[\"prop\"] for comp in comp_dict[\"smis\"].values() if comp[\"name\"]])\n",
    "    return mix_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/jr629406/login23-g-1_56382/ipykernel_249208/3862679337.py:29: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  mix_prop = 1 / sum([comp[\"frac\"] / comp[\"prop\"] for comp in comp_dict[\"smis\"].values() if comp[\"name\"]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mixtures that could be resolved by linear mixture rule: 8146\n",
      "R2: 0.9472362929856016\n",
      "MAE: 0.1605010957866922\n",
      "RMSE: 0.2403887142520247\n",
      "Number of mixtures that could be resolved by inverse linear mixture rule: 8146\n",
      "R2: -403.9968047641073\n",
      "MAE: 2.4196280068039977\n",
      "RMSE: 21.060671926846698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "for tc in target_columns:  \n",
    "    smiss = df_input_mix.loc[:, smiles_columns].values\n",
    "    fracs = df_input_mix.loc[:, frac_columns].values\n",
    "    comp_dicts = [{\"smis\": {sc: {\"name\": smis[sc_idx], \"frac\": frac[sc_idx]} for sc_idx, sc in enumerate(smiles_columns)}} for smis, frac in zip(smiss, fracs)]\n",
    "    tc = target_columns[0]\n",
    "    df_input_mix[f\"{tc}_linear\"] = np.nan    \n",
    "    df_input_mix[f\"{tc}_inv_linear\"] = np.nan   \n",
    "    df_input_mix.iloc[:, df_input_mix.columns.get_loc(f\"{tc}_linear\")] = np.array([prop_from_linear_mixing_rule(cd, df_input_pure, tc) for cd in comp_dicts])\n",
    "    df_input_mix.iloc[:, df_input_mix.columns.get_loc(f\"{tc}_inv_linear\")] = np.array([prop_from_inv_linear_mixing_rule(cd, df_input_pure, tc) for cd in comp_dicts])\n",
    "\n",
    "print(f\"Number of mixtures that could be resolved by linear mixture rule: {df_input_mix[f'{tc}_linear'].count()}\")\n",
    "mae = np.mean(np.abs(df_input_mix[f'{tc}_linear'] - df_input_mix[tc]))\n",
    "rmse = np.sqrt(np.mean(np.abs(df_input_mix[f'{tc}_linear'] - df_input_mix[tc])**2))\n",
    "mask = ~np.isnan(df_input_mix[f'{tc}_linear'])\n",
    "r2 = r2_score(df_input_mix[tc][mask], df_input_mix[f'{tc}_linear'][mask])\n",
    "print(f\"R2: {r2}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "smiss = df_input_pure.loc[:, smiles_columns].values\n",
    "fracs = df_input_pure.loc[:, frac_columns].values\n",
    "ys = df_input_pure.loc[:, target_columns].values\n",
    "print(len(smiss))\n",
    "all_data = [[ComponentDatapoint.from_smi(smis[0], y, w_fp=f[0]) for smis, y, f in zip(smiss, ys, fracs)]]\n",
    "all_data += [[ComponentDatapoint.from_smi(smis[1], w_fp=f[1]) if smis[1] else ComponentDatapoint(None) for smis, f in zip(smiss, fracs)]]\n",
    "all_data += [[ComponentDatapoint.from_smi(smis[2], w_fp=f[2]) if smis[2] else ComponentDatapoint(None) for smis, f in zip(smiss, fracs)]]\n",
    "all_data += [[ComponentDatapoint.from_smi(smis[3], w_fp=1-f[0]-f[1]-f[2]) if smis[3] else ComponentDatapoint(None) for smis, f in zip(smiss, fracs)]]\n",
    "print(len(all_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The return type of make_split_indices has changed in v2.1 - see help(make_split_indices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "component_to_split_by = 0  # index of the component to use for structure based splits\n",
    "mols = [d.mol for d in all_data[component_to_split_by]]\n",
    "train_indices, val_indices, test_indices = make_split_indices(mols, \"random\", (0.9, 0.1, 0))\n",
    "train_data, val_data, test_data = split_data_by_indices(\n",
    "    all_data, train_indices, val_indices, test_indices\n",
    ")\n",
    "train_data = train_data[0]\n",
    "print(len(train_data[0]))\n",
    "val_data = val_data[0]\n",
    "print(len(val_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8146\n"
     ]
    }
   ],
   "source": [
    "df_input_mix = df_input_mix[df_input_mix[f\"{target_columns[0]}_linear\"].notnull()]\n",
    "smiss = df_input_mix.loc[:, smiles_columns].values\n",
    "fracs = df_input_mix.loc[:, frac_columns].values\n",
    "ys = df_input_mix.loc[:, target_columns].values\n",
    "\n",
    "all_data = [[ComponentDatapoint.from_smi(smis[0], y, w_fp=f[0]) for smis, y, f in zip(smiss, ys, fracs)]]\n",
    "all_data += [[ComponentDatapoint.from_smi(smis[1], w_fp=f[1]) for smis, f in zip(smiss, fracs)]]\n",
    "all_data += [[ComponentDatapoint.from_smi(smis[2], w_fp=f[2]) if smis[2] else ComponentDatapoint(None) for smis, f in zip(smiss, fracs)]]\n",
    "all_data += [[ComponentDatapoint.from_smi(smis[3], w_fp=1-f[0]-f[1]-f[2]) if smis[3] else ComponentDatapoint(None) for smis, f in zip(smiss, fracs)]]\n",
    "\n",
    "test_data = all_data\n",
    "print(len(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = [\n",
    "    ComponentDataset(train_data[0]),\n",
    "    ComponentDataset(train_data[1]),\n",
    "    ComponentDataset(train_data[2]),\n",
    "    ComponentDataset(train_data[3]),\n",
    "]\n",
    "val_datasets = [\n",
    "    ComponentDataset(val_data[0]),\n",
    "    ComponentDataset(val_data[1]),\n",
    "    ComponentDataset(val_data[2]),\n",
    "    ComponentDataset(val_data[3]),\n",
    "]\n",
    "test_datasets = [\n",
    "    ComponentDataset(test_data[0]),\n",
    "    ComponentDataset(test_data[1]),\n",
    "    ComponentDataset(test_data[2]),\n",
    "    ComponentDataset(test_data[3]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mcdset = MixtureDataset(train_datasets)\n",
    "scaler = train_mcdset.normalize_targets()\n",
    "val_mcdset = MixtureDataset(val_datasets)\n",
    "val_mcdset.normalize_targets(scaler)\n",
    "test_mcdset = MixtureDataset(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_mcdset, batch_size=4, shuffle=True, collate_fn=collate_mixture)\n",
    "val_loader = DataLoader(val_mcdset, batch_size=10, shuffle=False, collate_fn=collate_mixture)\n",
    "test_loader = DataLoader(test_mcdset, batch_size=100, shuffle=False, collate_fn=collate_mixture)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leakyrelu\n",
      "leakyrelu\n",
      "leakyrelu\n"
     ]
    }
   ],
   "source": [
    "mp_depth = 4\n",
    "mp_dh = 200\n",
    "groups = [[0,1,2,3]]\n",
    "\n",
    "mcmp = MulticomponentMessagePassing(\n",
    "    blocks=[\n",
    "        BondMessagePassing(depth=mp_depth, d_h=mp_dh, activation=\"leakyrelu\")\n",
    "        ],  \n",
    "        groups=groups, \n",
    "        shared=False\n",
    "        )\n",
    "\n",
    "mixmp = MixtureMessagePassing(\n",
    "    d_v=mcmp.blocks[0].output_dim, \n",
    "    d_h=mcmp.blocks[0].output_dim, \n",
    "    depth=1, \n",
    "    activation=\"leakyrelu\"\n",
    "    )\n",
    "\n",
    "graph_agg = MeanAggregation()\n",
    "name_agg = \"weightedsum\"\n",
    "use_mixmp = False\n",
    "if not use_mixmp:\n",
    "    mixmp = None\n",
    "\n",
    "match name_agg:\n",
    "    case \"weightedsum\":\n",
    "        mixagg = WeightedSumAggregation(\n",
    "            graph_agg=graph_agg, groups=groups, fp_dims=[mcmp.blocks[0].output_dim] * 4, mixmp=mixmp,\n",
    "        )\n",
    "    case \"cat\":\n",
    "        mixagg = ConcatAggregation(\n",
    "            graph_agg=graph_agg, groups=groups, fp_dims=[mcmp.blocks[0].output_dim] * 4, mixmp=mixmp,\n",
    "        )\n",
    "    case \"deepsets\":\n",
    "        mixagg = DeepsetsAggregation(\n",
    "            graph_agg=graph_agg, groups=groups, fp_dims=[mcmp.blocks[0].output_dim] * 4, mixmp=mixmp,\n",
    "        )\n",
    "    case \"attentive\":\n",
    "        mixagg = AttentiveAggregation(\n",
    "            graph_agg=graph_agg, groups=groups, fp_dims=[mcmp.blocks[0].output_dim] * 4, mixmp=mixmp,\n",
    "        )\n",
    "    case \"set2set\":\n",
    "        mixagg = Set2SetAggregation(\n",
    "            graph_agg=graph_agg, groups=groups, fp_dims=[mcmp.blocks[0].output_dim] * 4, mixmp=mixmp,\n",
    "        )\n",
    "    case _:\n",
    "        raise ValueError(f\"MixtureAggregation {name_agg} not implemented yet.\")\n",
    "\n",
    "output_transform = UnscaleTransform.from_standard_scaler(scaler)\n",
    "ffn_activation = \"leakyrelu\"\n",
    "ffn = RegressionFFN(input_dim=mixagg.output_dim, output_transform=output_transform, \n",
    "        hidden_dim=500,\n",
    "        n_layers=4,\n",
    "        activation=ffn_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixtureMPNN(\n",
       "  (message_passing): MulticomponentMessagePassing(\n",
       "    (blocks): ModuleList(\n",
       "      (0-3): 4 x BondMessagePassing(\n",
       "        (W_i): Linear(in_features=86, out_features=200, bias=False)\n",
       "        (W_h): Linear(in_features=200, out_features=200, bias=False)\n",
       "        (W_o): Linear(in_features=272, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (tau): LeakyReLU(negative_slope=0.1)\n",
       "        (V_d_transform): Identity()\n",
       "        (graph_transform): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (agg): Set2SetAggregation(\n",
       "    (graph_agg): MeanAggregation()\n",
       "    (lstms): ModuleList(\n",
       "      (0): LSTM(400, 200)\n",
       "    )\n",
       "  )\n",
       "  (bn): Identity()\n",
       "  (predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=400, out_features=500, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): LeakyReLU(negative_slope=0.1)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=500, out_features=500, bias=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): LeakyReLU(negative_slope=0.1)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=500, out_features=500, bias=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): LeakyReLU(negative_slope=0.1)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=500, out_features=500, bias=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): LeakyReLU(negative_slope=0.1)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=500, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[1.0]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (X_d_transform): Identity()\n",
       "  (metrics): ModuleList(\n",
       "    (0): MSE(task_weights=[[1.0]])\n",
       "    (1): RMSE(task_weights=[[1.0]])\n",
       "    (2): MAE(task_weights=[[1.0]])\n",
       "    (3): R2Score()\n",
       "    (4): MSE(task_weights=[[1.0]])\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmpnn = MixtureMPNN(mcmp, mixagg, ffn, metrics=[MSE(), RMSE(), MAE(), R2Score()])\n",
    "mcmpnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjangerit\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250225_191437-ha01d2w7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jangerit/svt-gnn4pp/runs/ha01d2w7' target=\"_blank\">fuel_shared_set2set_mixmpFalse_leakyrelu</a></strong> to <a href='https://wandb.ai/jangerit/svt-gnn4pp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jangerit/svt-gnn4pp' target=\"_blank\">https://wandb.ai/jangerit/svt-gnn4pp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jangerit/svt-gnn4pp/runs/ha01d2w7' target=\"_blank\">https://wandb.ai/jangerit/svt-gnn4pp/runs/ha01d2w7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"svt-gnn4pp\", group=\"chemprop_fuel_pure\", name=f\"fuel_shared_{name_agg}_mixmp{str(use_mixmp)}_{ffn_activation}\")\n",
    "wandb_logger.log_hyperparams(mcmpnn.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rwth1232/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/rwth1232/anaconda3/envs/chemprop/lib/python3.1 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=wandb_logger,\n",
    "    enable_checkpointing=True,\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA H100') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/rwth1232/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name            | Type                         | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0 | message_passing | MulticomponentMessagePassing | 111 K  | train\n",
      "1 | agg             | Set2SetAggregation           | 481 K  | train\n",
      "2 | bn              | Identity                     | 0      | train\n",
      "3 | predictor       | RegressionFFN                | 952 K  | train\n",
      "4 | X_d_transform   | Identity                     | 0      | train\n",
      "5 | metrics         | ModuleList                   | 0      | train\n",
      "-------------------------------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "6.184     Total estimated model params size (MB)\n",
      "38        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rwth1232/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 59/59 [00:00<00:00, 74.14it/s, v_num=d2w7, train_loss_step=0.00223, val_loss=0.218, train_loss_epoch=0.00869] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 59/59 [00:00<00:00, 68.19it/s, v_num=d2w7, train_loss_step=0.00223, val_loss=0.218, train_loss_epoch=0.00869]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(mcmpnn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/rwth1232/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 82/82 [00:02<00:00, 34.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36773622035980225    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2907654643058777     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test/r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7345089316368103     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/rmse         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5392267107963562     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/mae         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36773622035980225   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2907654643058777    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test/r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7345089316368103    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/rmse        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5392267107963562    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cresults = trainer.test(mcmpnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader_met' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtest(mcmpnn, \u001b[43mtrain_loader_met\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader_met' is not defined"
     ]
    }
   ],
   "source": [
    "results = trainer.test(mcmpnn, train_loader_met)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Assuming your dataframe is called 'df'\n",
    "\n",
    "# Group the dataframe by smiles_1, smiles_2, and t_norm\n",
    "grouped = df_input_mix.groupby(['smiles_string_surfactant_1', 'smiles_string_surfactant_2', 'T_norm'])\n",
    "\n",
    "os.makedirs(\"CMC_plots\", exist_ok=True)\n",
    "\n",
    "# Iterate through each group\n",
    "for i, (name, group) in enumerate(grouped):\n",
    "    if i >= 5: break\n",
    "\n",
    "    smiles_1, smiles_2, smiles_3, smiles_4 = name\n",
    "\n",
    "    fs = np.arange(0, 1, 0.01)\n",
    "\n",
    "    print(type(t_norm))\n",
    "\n",
    "    all_data = [[ComponentDatapoint.from_smi(smiles_1, w_fp=f, x_d=np.array([t_norm])) for f in fs]]\n",
    "    all_data += [[ComponentDatapoint.from_smi(smiles_2, w_fp=1-f) for f in fs]]\n",
    "    tmp_dataset = [\n",
    "        ComponentDataset(all_data[0]),\n",
    "        ComponentDataset(all_data[1]),\n",
    "    ]\n",
    "\n",
    "    tmp_loader = DataLoader(MixtureDataset(tmp_dataset), batch_size=100, shuffle=False, collate_fn=collate_mixture)\n",
    "    ys = trainer.predict(mcmpnn, tmp_loader)\n",
    "    ys = np.concatenate(torch.cat(ys, dim=1).detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    # Create a new figure for each group\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    y_pure_2 = df_input_pure[(df_input_pure[smiles_columns[0]] == smiles_1) & (df_input_pure[\"T_norm\"] == t_norm)][\"log_CMC\"].values\n",
    "    y_pure_1 = df_input_pure[(df_input_pure[smiles_columns[0]] == smiles_2) & (df_input_pure[\"T_norm\"] == t_norm)][\"log_CMC\"].values\n",
    "    print(y_pure_1)\n",
    "    # Plot the three curves\n",
    "    sns.scatterplot(x=[0,1], y=[y_pure_1[0], y_pure_2[0]], label='Experimental pure', marker=\"o\", color=\"red\")\n",
    "    sns.scatterplot(data=group, x='ratio_1', y='log_CMC', label='Experimental', marker='o', color='black')\n",
    "    sns.lineplot(data=group, x='ratio_1', y='log_CMC_inv_linear', label='Inverse linear mixing rule', marker='s')\n",
    "    sns.lineplot(x=fs, y=ys, label='Predicted mix', marker='^')\n",
    "    \n",
    "    # Set labels and title\n",
    "    plt.xlabel('Ratio 1')\n",
    "    plt.ylabel('log_CMC')\n",
    "    plt.title(f'Comparison for {smiles_1}, {smiles_2}, t_norm={t_norm}')\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "    \n",
    "    # Improve layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure (optional)\n",
    "    plt.savefig(f'CMC_plots/plot_{smiles_1}_{smiles_2}_{t_norm}_{name_agg}_{ffn_activation}.png')\n",
    "    \n",
    "    # Show the plot (comment this out if you're generating many plots)\n",
    "    plt.show()\n",
    "    \n",
    "    # Close the figure to free up memory\n",
    "    plt.close()\n",
    "\n",
    "# Set the style for all plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"deep\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
